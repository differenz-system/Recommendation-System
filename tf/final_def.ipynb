{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f26c259",
   "metadata": {},
   "source": [
    "# Import  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7cfdba-0b1e-4973-aa7e-a8a7b7d87002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b8ce4",
   "metadata": {},
   "source": [
    "# Load cleaned data for tensorflow which is preprocess using data_preprocessing funtion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0769039",
   "metadata": {},
   "source": [
    "In tensorflow model we need:\n",
    "    -Product id\n",
    "    -Product category\n",
    "    -Product Description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff18ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_df(site_id):\n",
    "\n",
    "    path = 'dataset/tf_data/tensor_data.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    df['product_id'] = df['product_id'].astype('str')\n",
    "\n",
    "    product_df = df.copy()\n",
    "    product_df.drop(['short_description'], axis=1, inplace=True)\n",
    "    products1 = tf.data.Dataset.from_tensor_slices(dict(product_df))\n",
    "    products = products1.map(lambda x: x[\"product_id\"])\n",
    "\n",
    "    category1 = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "    category = category1.map(lambda x: {\n",
    "        \"short_description\": x['short_description'],\n",
    "        \"product_id\": x['product_id']\n",
    "    })\n",
    "    \n",
    "    return products, category, df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "898794a5",
   "metadata": {},
   "source": [
    "Creates a vocabulary for product IDs using TensorFlow's StringLookup layer. Additionally, it generates a vocabulary for product categories based on unique short descriptions using the StringLookup layer. The function returns these two vocabulary layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddb54ef-cc8b-429d-98ca-5a19ba61c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(site_id):\n",
    "    \n",
    "    df=product_df(site_id)\n",
    "    product_df1=df[2]\n",
    "\n",
    "    ids=product_df1['product_id'].values.tolist()\n",
    "    product_ids_vocabulary = tf.keras.layers.StringLookup(vocabulary=ids,mask_token=None)\n",
    "    \n",
    "    \n",
    "    df3=product_df1.copy()\n",
    "\n",
    "    df3.drop_duplicates(subset=\"short_description\",inplace=True)\n",
    "    cat=df3['short_description'].values.tolist()\n",
    "    product_category_vocabulary = tf.keras.layers.StringLookup(vocabulary=cat,mask_token=None)\n",
    "    \n",
    "    return product_ids_vocabulary, product_category_vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0557bb83",
   "metadata": {},
   "source": [
    "Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b9e4ba-acc0-455c-b670-c1a373c08d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "    def __init__(self,product_model: tf.keras.Model,category_model: tf.keras.Model,task: tfrs.tasks.Retrieval):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set up user and movie representations.\n",
    "        self.product_model = product_model\n",
    "        self.category_model = category_model\n",
    "\n",
    "        # Set up a retrieval task.\n",
    "        self.task = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "        product_embeddings = self.product_model(features[\"product_id\"])\n",
    "        category_embeddings = self.category_model(features[\"short_description\"])\n",
    "\n",
    "        return self.task(product_embeddings, category_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b7cd3c-f794-44d2-9977-022a0bceaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(site_id):\n",
    "    \n",
    "    vo=vocabulary(site_id)\n",
    "    product_ids_vocabulary=vo[0]\n",
    "    product_category_vocabulary=vo[1]\n",
    "    \n",
    "    # Define user and movie models.\n",
    "    product_model = tf.keras.Sequential([\n",
    "        product_ids_vocabulary,\n",
    "        tf.keras.layers.Embedding(product_ids_vocabulary.vocabulary_size(), 64)\n",
    "    ])\n",
    "    category_model = tf.keras.Sequential([\n",
    "        product_category_vocabulary,\n",
    "        tf.keras.layers.Embedding(product_category_vocabulary.vocabulary_size(), 64)\n",
    "    ])\n",
    "    \n",
    "    return product_model,category_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "571b04e1-b9ba-4b09-8e11-ee6863323630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1(site_id):\n",
    "    \n",
    "    \n",
    "    \n",
    "    data=product_df(site_id)\n",
    "    products=data[0]\n",
    "\n",
    "    cat_mod=neural_net(site_id)\n",
    "    product_model=cat_mod[0]\n",
    "    \n",
    "    # Define your objectives.\n",
    "    task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "        products.batch(128).map(product_model)\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640afae",
   "metadata": {},
   "source": [
    "# For training the tf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf095604-7944-4905-be41-f5a42bc20460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(site_id):\n",
    "    \n",
    "    df=product_df(site_id)\n",
    "    category=df[1]\n",
    "    \n",
    "    neural=neural_net(site_id)\n",
    "    product_model=neural[0]\n",
    "    category_model=neural[1]\n",
    "    \n",
    "    task=task1(site_id)\n",
    "    \n",
    "    # Create a retrieval model.\n",
    "    model = MovieLensModel(product_model, category_model, task)\n",
    "    model.compile(optimizer = 'Adam', loss = 'mse') #metrics = ['accuracy']\n",
    "\n",
    "\n",
    "    # Train for 3 epochs.\n",
    "    model.fit(category.batch(50), epochs=3)\n",
    "    \n",
    "    path=path='dataset/tf_model/model'\n",
    "    model.save_weights(path, save_format='tf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train('1')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55573b75",
   "metadata": {},
   "source": [
    "After training the model you can use trained model by loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c278de98-f9ac-4141-9a91-1480845751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(site_id):\n",
    "    \n",
    "    df=product_df(site_id)\n",
    "    products=df[0]\n",
    "    \n",
    "    neural=neural_net(site_id)\n",
    "    product_model=neural[0]\n",
    "    category_model=neural[1]\n",
    "    \n",
    "    task=task1(site_id)\n",
    "\n",
    "    model = RecommendModel(product_model, category_model, task)\n",
    "    \n",
    "    path='dataset/tf_model/model'\n",
    "    model.load_weights(path)\n",
    "    \n",
    "    # Use brute-force search to set up retrieval using the trained representations.\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.category_model)\n",
    "    index.index_from_dataset(\n",
    "        products.batch(100).map(lambda title: (title, model.product_model(title))))\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa6e4f52-92ea-467a-a1f6-495914c48136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(site_id,pid):\n",
    "    \n",
    "    data=product_df(site_id)\n",
    "    df=data[2]\n",
    "    \n",
    "    index=load_model(site_id)\n",
    "    \n",
    "    p_id=str(pid)\n",
    "    test=df[(df['product_id']==p_id)]\n",
    "    reco=test['short_description'].tolist()\n",
    "    for i in reco:\n",
    "        # Get some recommendations.\n",
    "        _, titles = index(np.array([i]))\n",
    "        #print(f\"Top 10 recommendations for product id {p_id}: {titles}\")\n",
    "        \n",
    "    ids=pd.DataFrame(titles)\n",
    "    reco_id=ids.values.tolist()\n",
    "    reco_id=[ int(j.decode()) for i in reco_id for j in i]\n",
    "    \n",
    "    return reco_id"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e357621a",
   "metadata": {},
   "source": [
    "You need to provide the path and product id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f084e6ea-7495-446c-82b0-48dc3f6cd505",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[115947,\n",
       " 116918,\n",
       " 113761,\n",
       " 116166,\n",
       " 115362,\n",
       " 117164,\n",
       " 115049,\n",
       " 116582,\n",
       " 116507,\n",
       " 113268]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_id=recommendation('1',95782)\n",
    "reco_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06799514-8bce-485d-a9da-40fd98175b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bottle - Bri Glass, With Cover, Blue Flower',\n",
       " 'Stainless Steel Water Bottle - Silver, BB 492 1',\n",
       " 'Trendy Stainless Steel Bottle With Sipper Cap - Steel Matt Finish, PXP 1002 CQ',\n",
       " 'Plastic Bottle - Narrow Neck, Blue, Apollo, 20371BL',\n",
       " 'Glass Water Bottle With Square Base - Blue, BB 1360',\n",
       " 'Plastic Bottle - Narrow Neck, Green, Apollo, 20371GN',\n",
       " 'Leo Plastic Pet Water Bottle - White, Wide Mouth',\n",
       " 'Aqua Stainless Steel Bottle With Steel Cap - Steel Mirror Finish, PXP 1003 CK',\n",
       " 'Frost Stainless Steel Bottle With Sipper Cap - Steel Mirror Finish, PXP 1004 CQ',\n",
       " 'Whip Insulated Water Bottle - Red']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reco_name_testing():\n",
    "    df=pd.read_csv('dataset/tf_data/tensor_data.csv')\n",
    "    name=[]\n",
    "    for i in reco_id:\n",
    "        idx=df[(df['product_id']==i)].index.values\n",
    "        for j in idx:\n",
    "            name1=df['product_name'].iloc[j]\n",
    "            name.append(name1)\n",
    "    return name\n",
    "reco_name_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04233f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
